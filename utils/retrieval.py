from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
import os

model = SentenceTransformer('all-MiniLM-L6-v2')

def retrieve_context(file_id: str, question: str, top_k: int = 5, index_dir: str = "indices") -> list:
    print(f"ğŸ“¥ [retrieve_context] æ­£åœ¨å¤„ç† file_id={file_id}, question={question}")

    index_path = os.path.join(index_dir, f"{file_id}.index")
    text_path = os.path.join(index_dir, f"{file_id}.txt")

    # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(index_path):
        print(f"âŒ ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨: {index_path}")
        raise FileNotFoundError(f"ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨ï¼š{index_path}")
    if not os.path.exists(text_path):
        print(f"âŒ æ–‡æœ¬æ–‡ä»¶ä¸å­˜åœ¨: {text_path}")
        raise FileNotFoundError(f"æ–‡æœ¬æ–‡ä»¶ä¸å­˜åœ¨ï¼š{text_path}")

    # åŠ è½½æ•°æ®
    index = faiss.read_index(index_path)
    with open(text_path, 'r', encoding='utf-8') as f:
        chunks = f.read().split("%%%\n")
    print(f"ğŸ“„ æ®µè½æ•°é‡: {len(chunks)}")

    # ç”ŸæˆæŸ¥è¯¢å‘é‡
    try:
        q_vec = model.encode([question], convert_to_numpy=True)
    except Exception as e:
        print(f"âŒ é—®é¢˜ embedding å¤±è´¥: {e}")
        raise

    # FAISS æœç´¢
    try:
        distances, indices = index.search(q_vec, top_k)
        print(f"ğŸ” FAISS æœç´¢å®Œæˆï¼Œè¿”å›ç´¢å¼•: {indices}")
    except Exception as e:
        print(f"âŒ FAISS æŸ¥è¯¢å¤±è´¥: {e}")
        raise

    # å–å‡ºæ®µè½
    result = [chunks[i] for i in indices[0] if i < len(chunks)]
    print(f"âœ… è¿”å›æ®µè½æ•°: {len(result)}")
    return result
